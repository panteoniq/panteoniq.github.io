---
title: [스레드 풀/Thread Pool] 스레드 풀의 적정 크기는? / 스레드 풀의 적절한 사이즈는?
date: 2022-11-10 21:04:10 +0900
categories: [Development, Etc]
tags: [Thread, 스레드, 동시성]
---
스레드 풀의 적정 사이즈는 어느 정도일까요? 1개? 2개? 또는 최대한 많이? 적절한 답을 찾지 못해 구글링하던 도중 이에 대해 잘 정리된 글을 읽고 번역해보았습니다. 다소 부족한 부분이 있더라도 양해 부탁드리며, 원문을 보고 싶으시다면 다음을 참고 바랍니다.

원문 : **https://jobs.zalando.com/tech/blog/how-to-set-an-ideal-thread-pool-size/?gh_src=4n3gxh1**

--------------------------------------------------------------------

자바에서 스레드를 생성하는 것은 공짜가 아니다! 실제 오버헤드는 플랫폼마다 다르겠지만, 스레드가 생성될 때는 요청이 처리되는 지연 시간이 발생하고 JVM과 OS에 의한 추가적인 처리 과정이 필요하다. 그렇기 때문에 스레드 풀이 필요하다. 스레드 풀은 현재의 작업을 수행하기 위해 이전에 생성된 스레드 풀을 재사용함으로써 사이클 오버헤드 및 자원 낭비를 막을 수 있다.

*(역주 - 자원 낭비(problem of resource thrashing) - thrashing은 CPU가 작업 수행 시간보다 페이징 교체에 더 많은 시간을 소모하는 것을 의미. 즉 page fault가 많은 상황에 발생)*

이 글에서는 최적의 스레드 풀 사이즈에 대해 얘기하려고 한다. 잘 조정된 스레드 풀은 시스템의 최대치를 이끌어낼 수 있으며 최대치의 부하를 받을 때에도 올바르게 동작할 수 있다. 반면에 엉망인 스레드 풀을 사용할 경우, 스레드 풀이 있음에도 병목현상이 발생하거나 스레드 풀로 인해 프로그램이 죽을 수도 있다.



#### **스레드 풀에 제한을 걸어야 하는 이유는?**

여기에 Executors.newChachedThread을 구현한 코드가 있다. 우리는 왜 다음 코드를 그냥 쓰면 안 될까?

```
/** 
Thread Pool constructor 
*/
public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue {
	...
} 

/** Cached Thread Pool */
public static ExecutorService newCachedThreadPool() {
	return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>());
}
```

위 코드에서 스레드를 생성하는 데에 사용되는 SynchronousQueue는 풀 안에 있는 모든 스레드가 busy 상태일 경우 새로운 작업이 발생하면 새로운 스레드가 생성되는 것을 의미한다.
이는 자원의 추가 소모를 의미하고, 위 코드를 그대로 사용했을 때 만약 엄청나게 많은 요청이 발생한다면, 스레드가 계속 생성되다가 결국 OOM이 발생할 것이다.

즉 사용자 세션마다 스레드를 생성하게 된다면 DDoS와 동일한 문제가 발생하는 것이며, 서버는 이러한 상황이 발생하지 않도록 자원을 최대한 아껴야 한다. 

 

#### **네 한계를 알라**

첫번째로, 스레드 풀의 사이즈를 조정하기 전에 **관련된 환경의 제약 사항**을 확실히 이해해야만 한다. 이는 하드웨어만을 의미하는 것이 아니다.

1. 예를 들어 특정 스레드(worker)가 DB와 연관된 작업을 할 경우, 스레드 풀은 DB의 Connection Pool size에 영향을 받을 것이다.
   - 동시접속이 100개만 가능한 DB에 크기가 1000인 스레드 풀이 있다고 하면, 과연 스레드 풀은 효율적으로 동작할 수 있을까?
2. 한 스레드가 n개의 동시 요청을 처리할 수 있는 외부 서비스를 호출할 때, 스레드 풀의 크기는 이 '외부 서비스'의 성능에 따라 좌우된다.

이는 당연하지만 우리가 종종 잊는 것이다.

두번째로, 스레드 풀에게 중요한 자원 중 하나는 **CPU**다. 우리는 CPU의 전체 개수를 다음과 같이 구할 수 있다.

```
(Java)
int numOfCores = Runtime.getRuntime().availableProcessors();

(C)
#include <stdio.h>
#include <sys/sysinfo.h>
printf("%d processors configured and %d processors available.\n", get_nprocs_conf(), get_nprocs()); 

(Python)
import multiprocessing
multiprocessing.cpu_count()
```

위 코드들은 우리가 이전부터 CPU의 개수를 구할 때 써온 방법이다. 하지만 Docker와 같은 컨테이너 환경에서 실행해야 하는 경우라면 이 명령어를 사용할 때 주의해야 한다. 명령어를 실행한 컨테이너가 아니라, 컨테이너들을 제어하는 부모 host의 하드웨어 환경을 볼 수도 있기 때문이다.

이와 관련된 기사 2개를 첨부하겠으니 읽어보길 바란다.

(https://mjg123.github.io/2018/01/10/Java-in-containers-jdk10.html)

(https://jaxenter.com/nobody-puts-java-container-139373.html)

세 번째로, **메모리와 File handler, Socket Handler** 역시 중요하게 고려되어야 한다.
(File Descriptor는 linux 환경일 경우 기본적으로 1024개까지 open 가능하다)

 

#### **공식**

Brian Goetz의 유명한 책인 "Java Concurrency in Practice"에서는 다음 공식이 등장한다.

`스레드 수 = 사용 가능한 코어 수 * (1+대기 시간/실제 수행시간)`

*(역주 -  (대기 시간/서비스 시간)의 값은 block 계수라고도 한다.)*

여기서 대기 시간은 작업 하나를 완료하기 위해 필요한 대기 시간, 즉 I/O waiting, 원격 서비스에 대한 HTTP response wating 등을 의미한다. 수행 시간은 대기 시간을 제외하고 작업이 실제로 동작 중인 시간, 즉 I/O waiting 이후 전달받은 데이터를 처리하는 과정을 의미한다.

이 경우 CPU를 많이 쓰는 계산 작업의 경우 대기를 거의 하지 않으므로 (대기 시간/서비스 시간)의 값이 0에 수렴하므로, 스레드 풀의 최대 수는 사용 가능한 코어의 수와 동일하다. 만약 모든 작업이 계산 작업이라면 이 정도면 충분하다. 그 이상은 불필요하다.

```
예) worker 스레드는 '요청에 대한 응답을 JSON으로 변환하고 몇 가지 규칙을 실행하는 'microservice’(이하 micro)' 를 호출한다. micro의 응답 시간은 50ms, 서비스 시간은 5ms이며 worker 스레드를 실행시키는 프로그램은 듀얼 코어 cpu에서 동작한다고 가정하자.
```

이때 적절한 스레드 풀 사이즈는

 `2 *(1+50/5) = 22`가 된다.

하지만 위의 예시는 너무 단순화되었다. 단순히 처리에만 중점을 두었기 때문에 HTTP 응답을 하는 대상 서버의 Connection Pool, JMS(자바 메시지 서비스) 요청, JDBC Connection Pool 과 같은 어플리케이션 외의 영역을 고려하지 않았다. 

만약 여러 클래스에서 각각의 스레드풀, 즉 한 프로세스에서 여러 개의 스레드풀이 존재하는 경우 각자의 워크로드에 따라 이 수치가 조정될 수 있다. 이 경우엔 CPU 목표 사용량을 추가하기만 하면 된다. 이때 CPU 목표 사용량은 0에서 1사이의 값이다.

스레드 수 = 사용 가능한 코어 수 * CPU 목표 사용량 * (1+대기 시간/실제 수행시간)



#### **리틀의 법칙**



이 장에서는 최적화된 스레드 풀의 사이즈를 구할 것이다. 우리는 이론적인 최대치와 측정할 수 있는 항목이 있다. 하지만 어떻게 병렬 worker의 수가 지연 시간과 처리량을 변경할 수 있을까?

리틀의 법칙은 이 질문에 대한 답이 될 수 있다. 이 법칙에서 시스템의 요청 수는 도착한 비율과 개별 요청을 처리하는 데 걸리는 평균 시간을 곱한 값과 같다. 이 공식을 사용하여 특정 대기 시간 수준에서 사전 정의된 처리량을 처리할 병렬 work 스레드의 수를 계산할 수 있을 것이다

L = λ * WL - 동시에 처리된 요청 수λ – 평균 도착 시간(?)W – 요청이 처리되기까지의 평균 대기 시간

이 공식을 이용하면, 우리는 시스템의 용량을 계산할 수 있다. 또는 안정적인 응답 시간이 보장되는, 1초당 발생하는 요청들을 다루기 위해 몇 개의 스레드가 동시에 동작해야 하는지 계산할 수 있다.

우리의 예로 돌아가보자. 우리는 평균 응답 시간이 55ms이며 스레드풀의 크기가 22인 서비스를 갖고 있다.

이 서비스에 대해 리틀의 법칙을 적용하면

22 / 0.055 = 400 (우리 서비스가 안정적으로 응답을 처리할 수 있는 1초당 최대 요청 수)

의 결과를 얻을 수 있다.